architecture:
  backbone: MobileNetV2
  input_shape: [160, 160, 3]
  pretrained: imagenet
  head: global_average_pooling -> dropout(0.3) -> dense(num_classes)

training:
  epochs_head: 20
  batch_size: 32
  optimizer_head: adam
  lr_head: 1e-4
  finetune_layers: 40
  finetune_epochs: 8
  optimizer_finetune: adam
  lr_finetune: 1e-5

preprocessing:
  sample_rate: 16000
  segment_duration: 1.0
  n_mels: 128
  n_fft: 2048
  hop_length: 512
  fmax: 8000
  resize: [160, 160]
  normalization: MobileNetV2 ((x-127.5)/127.5)

augmentation:
  config_file: augmentation_config.json
