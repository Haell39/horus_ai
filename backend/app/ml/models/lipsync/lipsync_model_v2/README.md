# SyncNet v2 - Lipsync Detection Model

Modelo de detec√ß√£o de dessincroniza√ß√£o √°udio/v√≠deo (lipsync) para integra√ß√£o com o sistema Horus.

## üìÅ Arquivos

| Arquivo | Tamanho | Descri√ß√£o |
|---------|---------|-----------|
| `syncnet_v2.keras` | ~56 MB | Modelo Keras completo |
| `syncnet_v2.tflite` | ~56 MB | Modelo TFLite |
| `syncnet_v2_q.tflite` | ~14 MB | Modelo TFLite quantizado (menor) |
| `syncnet_inference.py` | - | Script de infer√™ncia |
| `model_config.json` | - | Configura√ß√µes do modelo |

## üöÄ Uso R√°pido

### Python
```python
from syncnet_inference import SyncNetInference, analyze_video

# Op√ß√£o 1: Classe completa
model = SyncNetInference("syncnet_v2.keras")  # ou .tflite
result = model.predict("video.mp4")

print(result.status)       # SyncStatus.SINCRONIZADO ou DESSINCRONIZADO
print(result.confidence)   # 0.0 a 1.0
print(result.offset_ms)    # Offset em milissegundos

# Op√ß√£o 2: Fun√ß√£o simples
result = analyze_video("video.mp4")
print(result["status"])    # "sincronizado" ou "dessincronizado"
```

### CLI
```bash
python syncnet_inference.py video.mp4
python syncnet_inference.py video.mp4 syncnet_v2.tflite
```

## üìä Classes de Sa√≠da

| Classe | Descri√ß√£o |
|--------|-----------|
| `sincronizado` | √Åudio e v√≠deo est√£o sincronizados (offset < 80ms) |
| `dessincronizado` | √Åudio e v√≠deo est√£o dessincronizados (offset > 80ms) |
| `sem_fala` | N√£o foi poss√≠vel detectar fala no v√≠deo |

## üìê Especifica√ß√µes

### Input
- **V√≠deo**: 5 frames RGB, 224x224, normalizados [0,1]
- **√Åudio**: MFCC 13 coeficientes √ó 20 frames, sample rate 16kHz

### Output
- **classification**: Probabilidades [sync, desync, sem_fala]
- **offset_prediction**: Offset estimado em segundos

## ‚öôÔ∏è Requisitos

```
tensorflow>=2.10.0
opencv-python>=4.5.0
librosa>=0.9.0
numpy>=1.20.0
```

## üìà Performance

- **Acur√°cia Treino**: 100%
- **Acur√°cia Valida√ß√£o**: 100%
- **Acur√°cia Teste**: 100% (7/7 v√≠deos)

## üîß Integra√ß√£o com Horus

```python
# Exemplo de integra√ß√£o
from syncnet_inference import SyncNetInference

class HorusLipsyncAnalyzer:
    def __init__(self):
        self.model = SyncNetInference("syncnet_v2_q.tflite")
    
    def analyze(self, video_path):
        result = self.model.predict(video_path)
        return {
            "lipsync_ok": result.status.value == "sincronizado",
            "confidence": result.confidence,
            "error_type": "lipsync" if result.status.value == "dessincronizado" else None
        }
```

---
**Vers√£o**: 2.0.0  
**Data**: 2025-12-02  
**Framework**: TensorFlow/Keras 2.10
